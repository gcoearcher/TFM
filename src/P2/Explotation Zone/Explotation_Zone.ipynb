{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "143b6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql.functions import col, trim, lower, regexp_replace\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bd2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_landing = \"../../../delta_lake/csv\"\n",
    "path_creation = \"/delta_lake/creation\"\n",
    "path_exploitation = \"/delta_lake/exploitation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2f5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/22 22:02:00 WARN Utils: Your hostname, provira-ERAZER-P6705-MD61203, resolves to a loopback address: 127.0.1.1; using 192.168.1.55 instead (on interface wlo1)\n",
      "25/06/22 22:02:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/provira/anaconda3/envs/py_tfm_env/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/provira/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/provira/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6a109570-b15b-4526-a034-d40d154f02a3;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 230ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6a109570-b15b-4526-a034-d40d154f02a3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n",
      "25/06/22 22:02:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Delta Lake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e44e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='519522', text='i do feel badly about is being so rude mean and over the top in doing so', Emotion='neutral'),\n",
       " Row(_c0='519523', text='i feel its a part of my passionate nature that makes me a valuable human being', Emotion='neutral'),\n",
       " Row(_c0='519524', text='i feel a little jaded a little grey a little less than i was', Emotion='neutral'),\n",
       " Row(_c0='519525', text='i feel like i m rich even though i probably only square up on the middle class rung of the ladder but the place is not that nice', Emotion='neutral'),\n",
       " Row(_c0='519526', text='i feel very appreciative thankful and grateful', Emotion='neutral')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = spark.read.format(\"delta\").load(f\"{path_landing}\")\n",
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510db58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Emotion|\n",
      "+--------------------+\n",
      "|             boredom|\n",
      "|                love|\n",
      "|omg!!! loving thi...|\n",
      "|why the nazis stu...|\n",
      "| @user as forecas...|\n",
      "|so simple, but so...|\n",
      "|   #friday  xoxos...|\n",
      "|#tgif   #ff to my...|\n",
      "|@user don't forge...|\n",
      "|loved that season...|\n",
      "|@user pay of #ric...|\n",
      "|#gameshow   bull ...|\n",
      "|lack of access sp...|\n",
      "|family 5k @user #...|\n",
      "|@user fg introduc...|\n",
      "|@user the library...|\n",
      "|men's footjoy bla...|\n",
      "| @user a great #m...|\n",
      "|happy friday.   #...|\n",
      "|badminton bareng ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "Number of distinct Emotion labels: 78800 / 1100992\n"
     ]
    }
   ],
   "source": [
    "distinct_emotions = df_csv.select(\"Emotion\").distinct()\n",
    "distinct_emotions.show()\n",
    "\n",
    "count_distinct = df_csv.select(\"Emotion\").distinct().count()\n",
    "total = df_csv.select(\"Emotion\").count()\n",
    "print(f\"Number of distinct Emotion labels: {count_distinct} / {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3affab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             Emotion| count|\n",
      "+--------------------+------+\n",
      "|             neutral|674538|\n",
      "|                love| 39553|\n",
      "|           happiness| 27175|\n",
      "|                NULL| 18177|\n",
      "|             sadness| 17491|\n",
      "|              relief| 16729|\n",
      "|                hate| 15267|\n",
      "|               anger| 12356|\n",
      "|                 fun| 10075|\n",
      "|          enthusiasm|  9304|\n",
      "|            surprise|  6954|\n",
      "|               empty|  5542|\n",
      "|               worry|  4475|\n",
      "|           [deleted]|  3861|\n",
      "|#model   i love u...|   319|\n",
      "|             boredom|   126|\n",
      "|              #NAME?|   123|\n",
      "|        CakeDay--Bot|    96|\n",
      "|i finally found a...|    82|\n",
      "|aww yeah it's all...|    75|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get count per Emotion\n",
    "emotion_counts = df_csv.groupBy(\"Emotion\").count()\n",
    "\n",
    "# Order by count descending and take top 10\n",
    "top_10_emotions = emotion_counts.orderBy(col(\"count\").desc()).limit(20)\n",
    "\n",
    "top_10_emotions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='0', text='i seriously hate one subject to death but now i feel reluctant to drop it', Emotion='hate'),\n",
       " Row(id='1', text='im so full of life i feel appalled', Emotion='neutral'),\n",
       " Row(id='2', text='i sit here to write i start to dig out my feelings and i think that i am afraid to accept the possibility that he might not make it', Emotion='neutral'),\n",
       " Row(id='3', text='ive been really angry with r and i feel like an idiot for trusting him in the first place', Emotion='anger'),\n",
       " Row(id='4', text='i feel suspicious if there is no one outside like the rapture has happened or something', Emotion='neutral')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_clean = df_csv.dropna() \\\n",
    "    .withColumnRenamed(\"_c0\", \"id\") \\\n",
    "    .withColumnRenamed(\"Emotion\", \"emotion\") \\\n",
    "    .withColumn(\"text\", trim(col(\"text\"))) \\\n",
    "    .withColumn(\"text\", lower(col(\"text\"))) \\\n",
    "    .withColumn(\"text\", regexp_replace(col(\"text\"), r\"\\bi m\\b\", \"i'm\")) \\\n",
    "    .withColumn(\"text\", regexp_replace(col(\"text\"), r\"[^a-zA-Z0-9\\s']\", \"\"))  # keep letters, digits, spaces, apostrophes\n",
    "\n",
    "df_csv_clean.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_tfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
